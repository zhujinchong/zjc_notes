# 数据集

评估主要集中在自然语言理解、通用问题回答、代码、数学、科学知识、推理、多语言能力等能力上。

英语

| 数据集         | 语言 | 描述                                                         |
| -------------- | ---- | ------------------------------------------------------------ |
| MMLU           |      | 英文选择题测试，包括中学、高中、大学的多个学科               |
| MMLU-Pro       |      | 这是一个增强的数据集，旨在集成更具挑战性、以推理为主的问题，并将多项选择的选项从 4 个扩展到 10 个，以此来扩展广泛使用的 MMLU 基准。 |
| GPQA           |      | 该数据包含生物学、物理学和化学等多个学科领域共448个问题。    |
| Theorem QA     |      | 该数据集由人类专家以非常高的质量收集。以应用定理来解决具有挑战性的大学水平问题。 |
| BBH            |      | 是 BIG-Bench 的一个子集，BIG-Bench 是一个用于语言模型的多样化评估套件。 |
| HellaSwag      |      | 该数据集包含10万个问题-回答对，其中每个回答都是一个需要对上下文进行深入理解的反常或不寻常的答案。 |
| WindoGrande    |      | 一个包含 44k 问题的大规模数据集，灵感来自原始问题 WSC 设计，但进行了调整以改善规模和 数据集的硬度。 |
| ARC-C          |      | 多项选择题问答数据集，包含从 3 年级到 9 年级的科学考试问题。 |
| TruthfulQA     |      | 用来测试模型真实性性能好坏                                   |
| **MT-Bench**   |      | 和MMLU类似。                                                 |
| **Arena-Hard** |      | 使用 GPT-4-Turbo 作为判断器，将不同模型的响应与基线模型      |
|                |      |                                                              |

中文

| 数据集         | 语言 | 描述                                             |
| -------------- | ---- | ------------------------------------------------ |
| C-Eval         | zh   | 中文选择题测试，包括中学、高中、大学的多个学科   |
| CMMLU          | zh   | 综合性的中文评估基准                             |
| SuperCLUE      | zh   | 中文通用大模型综合性基准                         |
| GAOKAO-Bench   | zh   | 收集了2010-2022年全国高考卷的题目                |
| **AlignBench** | zh   | 智谱推出的中文评测领域关于人类对齐的大模型的评测 |

数学

| 数据集 | 语言 | 描述                          |
| ------ | ---- | ----------------------------- |
| GSM8K  | en   | 小学数学题目                  |
| MATH   | en   | 数学竞赛问题，包括ACM、AIME等 |

代码

| 数据集        | 语言 | 描述                                                         |
| ------------- | ---- | ------------------------------------------------------------ |
| HumanEval     | en   | 由 OpenAI 发布的 164 个手写的编程问题                        |
| MBPP          | en   | 大约 1,000 个众包 Python 编程问题                            |
| EvalPlus      | en   | 这个项目为【HumanEval】和【MBPP】等著名代码评估基准增加了多达数千个新的测试案例，提高了测试的严谨性。 |
| MultiPL-E     | en   | 支持 18 种编程语言。使用小型编译器将【HumanEval】和【MBPP】转换为其他语言 |
| LiveCodeBench | en   | LiveCodeBench为LLM的编码能力提供全面且无污染的评估。特别是，LiveCodeBench随着时间的推移不断从三个竞赛平台（LeetCode、AtCoder和CodeForces）的竞赛中收集新问题。目前，LiveCodeBench托管了2023年5月至2024年3月期间发布的400个高质量编码问题。 |

多语言

| 数据集              | 语言 | 描述 |
| ------------------- | ---- | ---- |
| Mulit-Exam          |      |      |
| Multi-Understanding |      |      |
| Multi-Mathematics   |      |      |
| Multi-Translation   |      |      |



# 评估框架

eval-scope/llmuses

OpenCompass

# OpenCompass



